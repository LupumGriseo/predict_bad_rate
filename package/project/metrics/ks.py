#from bna.lib import *
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from scipy import stats
from typing import List, Tuple, Set, Any, Dict, Union, Callable, Iterable
import seaborn as sns
import os

global is_train
global train_KS

is_train = True
train_KS = None

def decile_metrics(
        y_true:np.ndarray,
        y_pred:np.ndarray,
        num_decile: int = 10
) -> pd.DataFrame:
    """
    Calculates metrics of a model based on deciles, given the scores evaluated on a dataset.
    If the distribution is too concentrated at one end,
    it finds the best number of percentiles that
    fits the distribution (less than 10 buckets).

    Arguments:
        y_true: 1-D array with true labels
        y_pred: 1-D array with probabilities of positive class
        num_decile: int, number of deciles to calculate the metrics with.

     Returns:
         A dataframe with the detail of the KS calculation for each decile
         (or other percentile).
    """

    data_df = pd.DataFrame(
        dict(target=y_true, prob=y_pred, target0=(1-y_true))
    )

    for num_decile in reversed(range(3, 11)):
        try:
            data_df['bucket'] = pd.qcut(data_df["prob"], num_decile)
            break
        except:
            pass

    if ('bucket' not in data_df.columns):
        return np.nan

    grouped = data_df.groupby('bucket', as_index=False)
    metrics = pd.DataFrame()
    metrics['min_prob'] = grouped.min()["prob"]
    metrics['max_prob'] = grouped.max()["prob"]
    metrics['events'] = grouped.sum()["target"]
    metrics['nonevents'] = grouped.sum()['target0']

    metrics = metrics.sort_values(by="min_prob", ascending=False).reset_index(drop=True)
    metrics['event_rate'] = (metrics.events / data_df["target"].sum()).apply('{0:.2%}'.format)
    metrics['nonevent_rate'] = (metrics.nonevents / data_df['target0'].sum()).apply('{0:.2%}'.format)
    metrics['cum_eventrate'] = (metrics.events / data_df["target"].sum()).cumsum()
    metrics['cum_noneventrate'] = (metrics.nonevents / data_df['target0'].sum()).cumsum()
    metrics['KS'] = np.round(metrics['cum_eventrate'] - metrics['cum_noneventrate'], 3) * 100

    metrics["bad_rate"] = metrics.events / (metrics.events + metrics.nonevents)
    metrics["cum_bad_rate"] = metrics.apply(
        lambda x:
        metrics[metrics.max_prob <= x.max_prob].events.sum() /
        (metrics[metrics.max_prob <= x.max_prob].events.sum() +
         metrics[metrics.max_prob <= x.max_prob].nonevents.sum()),
        axis=1
    )

    metrics.index = range(1, 1 + num_decile)
    metrics.index.rename('Decile', inplace=True)

    return metrics


def decile_metrics_test_from_train(metrics_train: pd.DataFrame = None,
                                   y_true:np.ndarray = None,
                                   y_pred:np.ndarray = None) -> pd.DataFrame:
    """
    Calculates metrics of a model based on deciles (or other partitioning) previously set for another training dataset.

    Arguments:
        metrics_train: a pd.DataFrame with the detail of metrics such as the one generated by the
                       decile_metrics() function.

        y_pred: 1-D array with probabilities for the positive class

    Returns:
         a pd.DataFrame with the details of the calculation of the metrics for each decile (or other percentile)
         with the same characteristics as the one returned by the decile_metrics (() function.
    """
    metrics = pd.DataFrame()
    metrics['min_prob'] = metrics_train.min_prob
    metrics['max_prob'] = metrics_train.max_prob

    metrics["events"] = metrics.apply(
        lambda x: (
            (y_true == 1) & (y_pred >= x.min_prob) & (y_pred < x.max_prob)
        ).sum(),
        axis=1
    )
    metrics["nonevents"] = metrics.apply(
        lambda x: (
            (y_true == 0) & (y_pred >= x.min_prob) & (y_pred < x.max_prob)
        ).sum(),
        axis=1
    )

    metrics['event_rate'] = metrics.events / metrics.events.sum()
    metrics['nonevent_rate'] = metrics.nonevents / metrics.nonevents.sum()
    metrics['cum_eventrate'] = metrics['event_rate'].cumsum()
    metrics['cum_noneventrate'] = metrics['nonevent_rate'].cumsum()
    metrics['KS'] = np.round(metrics['cum_eventrate'] - metrics['cum_noneventrate'], 3) * 100

    metrics["bad_rate"] = metrics.events / (metrics.events + metrics.nonevents)
    metrics["cum_bad_rate"] = metrics.apply(
        lambda x:
        metrics[metrics.max_prob <= x.max_prob].events.sum() /
        (metrics[metrics.max_prob <= x.max_prob].events.sum() +
         metrics[metrics.max_prob <= x.max_prob].nonevents.sum()),
        axis=1
    )

    metrics.index = range(1, 1 + len(metrics_train))
    metrics.index.rename('Decile', inplace=True)
    return metrics

def ks_score(y_true:np.ndarray, y_pred:np.ndarray) -> float:
    '''Function to predict KS using Sklearn pipeline'''

    global is_train
    global train_KS

    if is_train:
        train_KS = decile_metrics(y_true, y_pred)
        is_train = False

        if (isinstance(train_KS, pd.DataFrame) and
                not pd.isnull(train_KS.KS.max())):
            return train_KS.KS.max()

        return np.nan
    else:
        is_train = True
        if (isinstance(train_KS, float) and np.isnan(train_KS)):
            return np.nan

        test_KS = decile_metrics_test_from_train(
            train_KS, y_true, y_pred
        )

        return test_KS.KS.max()
